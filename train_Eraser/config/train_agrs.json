{
    "seed": 42,
    "model_name_or_path": "../models/Llama2-7b-chat-hf/",
    "data_path": "../data/harm_data.json",
    "help_path": "../data/help_data.json",
    "algn_path": "../data/algn_data.json",
    "harmful_threshold": 1.8,
    "model_max_length": 1536,
    "pad_to_multiple_of": 8,
    "fp16": true,
    "r": 8,
    "lora_alpha": 16,
    "target_modules": [
            "q_proj",
            "v_proj"
    ],
    "lora_dropout": 0.05,
    "bias": "none",
    "task_type": "CAUSAL_LM",
    "training_batch_size": 64,
    "evaluation_batch_size": 64,
    "eval_size": 0,
    "micro_batch_size": 4,
    "dataloader_num_workers": 1,
    "num_train_epochs": 5,
    "learning_rate": 2e-5,
    "weight_decay": 0.0000,
    "lr_scheduler_type": "cosine",
    "warmup_steps": 0,
    "optim": "adamw_torch",
    "evaluation_strategy": "steps",
    "eval_steps": 1,
    "load_best_model_at_end": true,
    "metric_for_best_model": "loss",
    "greater_is_better": false,
    "include_inputs_for_metrics": false,
    "output_dir": "../outputs/Eraser_Llama2_7b_Lora/",
    "save_strategy": "steps",
    "save_steps": 20,
    "overwrite_output_dir": true,
    "save_total_limit": 20,
    "report_to": "none",
    "logging_steps": 1
}
